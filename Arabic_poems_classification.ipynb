{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JkwE3TjDQIeY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/train.csv')"
      ],
      "metadata": {
        "id": "VepztcMpQS7C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1APCtsp5Q5px",
        "outputId": "cff774b5-8ef6-4786-f2aa-85eb65e71923"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   labels                                               data\n",
              "0       8  أَنا الفقير وباللَه العظيم غني # لئن فقدتك في ...\n",
              "1      10  وَلوعاً بِيُمنَى نَمْنَمَتْها حَدِيقَةٌ # نَزْ...\n",
              "2      11  فيا منْ لم أزلْ أحظى لديه # بفضلٍ جامعٍ بابَ ا...\n",
              "3       9  وَسَلامٌ عَلَى ضَرِيحِكَ مَا أَهْ # دَتْ شَذَا...\n",
              "4       8  أمِنْتُ فقري لما قُلتُ عن ثِقَةٍ # أنْ لا جواد..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9d19098-3b4d-4582-97da-dc4843949faa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>أَنا الفقير وباللَه العظيم غني # لئن فقدتك في ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>وَلوعاً بِيُمنَى نَمْنَمَتْها حَدِيقَةٌ # نَزْ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>فيا منْ لم أزلْ أحظى لديه # بفضلٍ جامعٍ بابَ ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>وَسَلامٌ عَلَى ضَرِيحِكَ مَا أَهْ # دَتْ شَذَا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>أمِنْتُ فقري لما قُلتُ عن ثِقَةٍ # أنْ لا جواد...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9d19098-3b4d-4582-97da-dc4843949faa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9d19098-3b4d-4582-97da-dc4843949faa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9d19098-3b4d-4582-97da-dc4843949faa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.1)"
      ],
      "metadata": {
        "id": "va3ItTUWQ6mG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WkOkXy1vROmI",
        "outputId": "83e3201f-436b-460b-f8f6-b2834e4b44ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      labels                                               data\n",
              "1643       1  وتدرَجتْ فوق الخمائلِ غُدْرها # وتأرَجتْ بشذا ...\n",
              "5781      13  فَعايَنَ المَوتَ الَّذي مِنهُ هَرَب # وَمَن يَ...\n",
              "1098       6      وَقُلتَ لَيتَ بِكَفّي # عِنانَ جَرداءَ شَطبَه\n",
              "1513      11  فَلاَ عِنْدِي لَهُ نِعَمٌ تُجَازَى # وَلا لِي ...\n",
              "194        8  حُسنى دعتك الورى من جملة الرمل # كم مقلة عميت ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdc2bfcb-0757-4f74-9613-8e31baf9498c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1643</th>\n",
              "      <td>1</td>\n",
              "      <td>وتدرَجتْ فوق الخمائلِ غُدْرها # وتأرَجتْ بشذا ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5781</th>\n",
              "      <td>13</td>\n",
              "      <td>فَعايَنَ المَوتَ الَّذي مِنهُ هَرَب # وَمَن يَ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1098</th>\n",
              "      <td>6</td>\n",
              "      <td>وَقُلتَ لَيتَ بِكَفّي # عِنانَ جَرداءَ شَطبَه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>11</td>\n",
              "      <td>فَلاَ عِنْدِي لَهُ نِعَمٌ تُجَازَى # وَلا لِي ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>8</td>\n",
              "      <td>حُسنى دعتك الورى من جملة الرمل # كم مقلة عميت ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdc2bfcb-0757-4f74-9613-8e31baf9498c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdc2bfcb-0757-4f74-9613-8e31baf9498c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdc2bfcb-0757-4f74-9613-8e31baf9498c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.labels.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g2KNGkxzcBa",
        "outputId": "b29822f8-0034-4db6-9666-e1126598f551"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7     824\n",
              "11    814\n",
              "8     803\n",
              "0     785\n",
              "2     783\n",
              "10    783\n",
              "13    766\n",
              "9     753\n",
              "1     749\n",
              "4     627\n",
              "6     165\n",
              "5      76\n",
              "3      54\n",
              "12     43\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indx2label = {0: 'saree', 1: 'kamel', 2: 'mutakareb', 3: 'mutadarak',\n",
        "              4: 'munsareh', 5: 'madeed', 6: 'mujtath', 7: 'ramal', 8: 'baseet',\n",
        "              9: 'khafeef', 10: 'taweel', 11: 'wafer', 12: 'hazaj', 13: 'rajaz'}"
      ],
      "metadata": {
        "id": "8efSQAzhzQJW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess tha data"
      ],
      "metadata": {
        "id": "w4bvfzeVlu3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "cleaned_data = []\n",
        "\n",
        "for line in train['data']:\n",
        "  line = re.sub('\\(|\\)|:|«|»|#|\\!|؟|؛|،|ـ|\\.|,|\\?', '', line)\n",
        "  cleaned_data.append(line)"
      ],
      "metadata": {
        "id": "6jFd8YeHX2kz"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "damv8wvqYl3y",
        "outputId": "63df92fb-4463-4d7d-e2b9-87cb41774ec9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['وتدرَجتْ فوق الخمائلِ غُدْرها  وتأرَجتْ بشذا العبيرِ رياحُها',\n",
              " 'فَعايَنَ المَوتَ الَّذي مِنهُ هَرَب  وَمَن يَفوتُ قَدَراً إِذا اِقتَرَب',\n",
              " 'وَقُلتَ لَيتَ بِكَفّي  عِنانَ جَرداءَ شَطبَه',\n",
              " 'فَلاَ عِنْدِي لَهُ نِعَمٌ تُجَازَى  وَلا لِي عِنْدَهُ ذِمَمٌ تُرَاعَى',\n",
              " 'حُسنى دعتك الورى من جملة الرمل  كم مقلة عميت أرجعت ناظرها',\n",
              " 'عَجِبتُ مِنهُ يَشدو فَيَظهَرُ لِلأَس  ماعِ حُسنَ الإِعرابِ وَاللَحنِ',\n",
              " 'يا قَمَراً عُطِّلَ الظَلامُ بِهِ  يا دُرَّةً لَم يُكِنَّها الصَدَفُ',\n",
              " 'قد فاض في الأرض حيث البحر لم يفض  الحاملين من الأشياء أثقلها',\n",
              " 'يُثني عَلَيهِ مِنَ الأَوقاتِ أَربَعَةٌ  يَومٌ وَشَهرٌ وَأَعوامٌ وَآبادُ',\n",
              " 'هَطلاءُ تَضحَكَُ كُلُّ زَهرَةِ صَفحَةٍ  عَنها وَتُعشِبُ كُلُّ ساحَةِ دارِ']"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "letters = set(' '.join(cleaned_data))\n",
        "len(letters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2GfTK2jZT1M",
        "outputId": "38bb7975-5cba-4d4d-fe85-84f6a72d94bd"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chr2indx = {c:i+1 for i, c in enumerate(letters)}"
      ],
      "metadata": {
        "id": "qCPkfj9qcjEe"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = [[chr2indx[c] for c in line] for line in cleaned_data]"
      ],
      "metadata": {
        "id": "1TxrGmcHktKi"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max(len(line) for line in tokenized_data)"
      ],
      "metadata": {
        "id": "nwCR6O-vlbTP"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WtmJ1w_jLr5",
        "outputId": "97f51a6d-58e1-44ae-bd80-5c20d7edd28d"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "N0VsWqc5nNWo"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding\n",
        "x = pad_sequences(tokenized_data, max_length, padding='post', value=0)"
      ],
      "metadata": {
        "id": "71Qlz7f9tehj"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = train['labels']"
      ],
      "metadata": {
        "id": "qHF9kQ6wt9rE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1)"
      ],
      "metadata": {
        "id": "rFSooOn5wKfY"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wrapping the preprocessing to use on test data\n",
        "\n",
        "def preprocess_data(data, chr2indx, max_length=max_length):\n",
        "\n",
        "  cleaned_data = []\n",
        "\n",
        "  for line in data:\n",
        "    line = re.sub('\\(|\\)|:|«|»|#|\\!|؟|؛|،|ـ|\\.|,|\\?', '', line)\n",
        "    cleaned_data.append(line)\n",
        "  print(\"First 10 lines in the data:\\n\", cleaned_data[:10])\n",
        "\n",
        "\n",
        "  tokenized_data = [[chr2indx.get(c, -1) for c in line] for line in cleaned_data]\n",
        "  pad_sentences = pad_sequences(tokenized_data, max_length, padding='post', value=0)\n",
        "\n",
        "  return pad_sentences"
      ],
      "metadata": {
        "id": "wI-ba48YwWsa"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "1PaZt3B9wiG4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(indx2label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVWSOhRVx4NX",
        "outputId": "884eeb59-4d27-484f-eb75-541829b8e296"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model"
      ],
      "metadata": {
        "id": "5H_iWoBCmF3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer((max_length,)),\n",
        "    keras.layers.Embedding(len(chr2indx)+1, 256),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(200, return_sequences=True)),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n",
        "    keras.layers.GlobalAveragePooling1D(),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Dense(len(indx2label), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "7FRa_0tdwu46"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "qwGjGF--0GKK"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyKp6kJI0Qhl",
        "outputId": "b9cdb6ea-0520-4ee0-fc4c-b50c09f793f8"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 95, 256)           11776     \n",
            "                                                                 \n",
            " bidirectional_61 (Bidirecti  (None, 95, 400)          731200    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_62 (Bidirecti  (None, 95, 1024)         3739648   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_63 (Bidirecti  (None, 95, 1024)         6295552   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_64 (Bidirecti  (None, 95, 1024)         6295552   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_average_pooling1d_12  (None, 1024)             0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 14)                3598      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,339,726\n",
            "Trainable params: 17,339,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_delta=0.0001, min_lr=0.00001, verbose=1)\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('model_checkpoint.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early_stop = keras.callbacks.EarlyStopping(patience=5)"
      ],
      "metadata": {
        "id": "Uz5fsYbC0WIY"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, validation_data= (x_val, y_val), epochs = 50, batch_size= 128, \n",
        "          callbacks=[reduce_lr, checkpoint, early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j98mI9ee1Wbx",
        "outputId": "bf83b879-ffbf-461a-f973-5d4c014e1793"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 2.2919 - accuracy: 0.1896\n",
            "Epoch 1: val_accuracy improved from -inf to 0.29514, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 38s 458ms/step - loss: 2.2919 - accuracy: 0.1896 - val_loss: 2.0300 - val_accuracy: 0.2951 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.9743 - accuracy: 0.2825\n",
            "Epoch 2: val_accuracy improved from 0.29514 to 0.35616, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 24s 415ms/step - loss: 1.9743 - accuracy: 0.2825 - val_loss: 1.7924 - val_accuracy: 0.3562 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.8718 - accuracy: 0.3150\n",
            "Epoch 3: val_accuracy improved from 0.35616 to 0.36239, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 24s 424ms/step - loss: 1.8718 - accuracy: 0.3150 - val_loss: 1.7564 - val_accuracy: 0.3624 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.8139 - accuracy: 0.3312\n",
            "Epoch 4: val_accuracy did not improve from 0.36239\n",
            "57/57 [==============================] - 24s 416ms/step - loss: 1.8139 - accuracy: 0.3312 - val_loss: 1.7501 - val_accuracy: 0.3412 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.7939 - accuracy: 0.3333\n",
            "Epoch 5: val_accuracy improved from 0.36239 to 0.37111, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 24s 429ms/step - loss: 1.7939 - accuracy: 0.3333 - val_loss: 1.7331 - val_accuracy: 0.3711 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.7734 - accuracy: 0.3451\n",
            "Epoch 6: val_accuracy improved from 0.37111 to 0.38232, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 432ms/step - loss: 1.7734 - accuracy: 0.3451 - val_loss: 1.7155 - val_accuracy: 0.3823 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.7511 - accuracy: 0.3511\n",
            "Epoch 7: val_accuracy did not improve from 0.38232\n",
            "57/57 [==============================] - 24s 425ms/step - loss: 1.7511 - accuracy: 0.3511 - val_loss: 1.7758 - val_accuracy: 0.3462 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.7441 - accuracy: 0.3557\n",
            "Epoch 8: val_accuracy did not improve from 0.38232\n",
            "57/57 [==============================] - 24s 426ms/step - loss: 1.7441 - accuracy: 0.3557 - val_loss: 1.7144 - val_accuracy: 0.3524 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.7080 - accuracy: 0.3631\n",
            "Epoch 9: val_accuracy did not improve from 0.38232\n",
            "57/57 [==============================] - 24s 425ms/step - loss: 1.7080 - accuracy: 0.3631 - val_loss: 1.6910 - val_accuracy: 0.3823 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.8751 - accuracy: 0.3284\n",
            "Epoch 10: val_accuracy did not improve from 0.38232\n",
            "57/57 [==============================] - 24s 424ms/step - loss: 1.8751 - accuracy: 0.3284 - val_loss: 1.7322 - val_accuracy: 0.3699 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.7568 - accuracy: 0.3489\n",
            "Epoch 11: val_accuracy did not improve from 0.38232\n",
            "57/57 [==============================] - 24s 424ms/step - loss: 1.7568 - accuracy: 0.3489 - val_loss: 1.6884 - val_accuracy: 0.3811 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.6844 - accuracy: 0.3775\n",
            "Epoch 12: val_accuracy improved from 0.38232 to 0.42341, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 436ms/step - loss: 1.6844 - accuracy: 0.3775 - val_loss: 1.6246 - val_accuracy: 0.4234 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.6111 - accuracy: 0.4086\n",
            "Epoch 13: val_accuracy improved from 0.42341 to 0.46451, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 438ms/step - loss: 1.6111 - accuracy: 0.4086 - val_loss: 1.5281 - val_accuracy: 0.4645 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.4736 - accuracy: 0.4726\n",
            "Epoch 14: val_accuracy improved from 0.46451 to 0.53300, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 437ms/step - loss: 1.4736 - accuracy: 0.4726 - val_loss: 1.3877 - val_accuracy: 0.5330 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.3550 - accuracy: 0.5217\n",
            "Epoch 15: val_accuracy improved from 0.53300 to 0.56289, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 438ms/step - loss: 1.3550 - accuracy: 0.5217 - val_loss: 1.2574 - val_accuracy: 0.5629 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 1.2116 - accuracy: 0.5777\n",
            "Epoch 16: val_accuracy improved from 0.56289 to 0.60274, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 437ms/step - loss: 1.2116 - accuracy: 0.5777 - val_loss: 1.1683 - val_accuracy: 0.6027 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.9516 - accuracy: 0.6801\n",
            "Epoch 17: val_accuracy improved from 0.60274 to 0.72478, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 437ms/step - loss: 0.9516 - accuracy: 0.6801 - val_loss: 0.8665 - val_accuracy: 0.7248 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.7000 - accuracy: 0.7821\n",
            "Epoch 18: val_accuracy improved from 0.72478 to 0.82814, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 439ms/step - loss: 0.7000 - accuracy: 0.7821 - val_loss: 0.5926 - val_accuracy: 0.8281 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.8455\n",
            "Epoch 19: val_accuracy improved from 0.82814 to 0.86052, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 437ms/step - loss: 0.5015 - accuracy: 0.8455 - val_loss: 0.5101 - val_accuracy: 0.8605 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8938\n",
            "Epoch 20: val_accuracy improved from 0.86052 to 0.87547, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 436ms/step - loss: 0.3721 - accuracy: 0.8938 - val_loss: 0.4498 - val_accuracy: 0.8755 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.9155\n",
            "Epoch 21: val_accuracy improved from 0.87547 to 0.89539, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 437ms/step - loss: 0.2867 - accuracy: 0.9155 - val_loss: 0.3955 - val_accuracy: 0.8954 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9360\n",
            "Epoch 22: val_accuracy improved from 0.89539 to 0.90909, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 436ms/step - loss: 0.2274 - accuracy: 0.9360 - val_loss: 0.3915 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9470\n",
            "Epoch 23: val_accuracy did not improve from 0.90909\n",
            "57/57 [==============================] - 24s 426ms/step - loss: 0.1887 - accuracy: 0.9470 - val_loss: 0.3908 - val_accuracy: 0.9029 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9489\n",
            "Epoch 24: val_accuracy did not improve from 0.90909\n",
            "57/57 [==============================] - 24s 426ms/step - loss: 0.1691 - accuracy: 0.9489 - val_loss: 0.3874 - val_accuracy: 0.9041 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9625\n",
            "Epoch 25: val_accuracy did not improve from 0.90909\n",
            "57/57 [==============================] - 24s 426ms/step - loss: 0.1290 - accuracy: 0.9625 - val_loss: 0.3938 - val_accuracy: 0.9041 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9639\n",
            "Epoch 26: val_accuracy did not improve from 0.90909\n",
            "57/57 [==============================] - 24s 426ms/step - loss: 0.1215 - accuracy: 0.9639 - val_loss: 0.4466 - val_accuracy: 0.8979 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9590\n",
            "Epoch 27: val_accuracy improved from 0.90909 to 0.91407, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 438ms/step - loss: 0.1269 - accuracy: 0.9590 - val_loss: 0.3669 - val_accuracy: 0.9141 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9776\n",
            "Epoch 28: val_accuracy improved from 0.91407 to 0.92030, saving model to model_checkpoint.h5\n",
            "57/57 [==============================] - 25s 437ms/step - loss: 0.0788 - accuracy: 0.9776 - val_loss: 0.3660 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9853\n",
            "Epoch 29: val_accuracy did not improve from 0.92030\n",
            "57/57 [==============================] - 24s 426ms/step - loss: 0.0471 - accuracy: 0.9853 - val_loss: 0.3995 - val_accuracy: 0.9141 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9886\n",
            "Epoch 30: val_accuracy did not improve from 0.92030\n",
            "57/57 [==============================] - 24s 426ms/step - loss: 0.0375 - accuracy: 0.9886 - val_loss: 0.4307 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9907\n",
            "Epoch 31: val_accuracy did not improve from 0.92030\n",
            "57/57 [==============================] - 24s 426ms/step - loss: 0.0360 - accuracy: 0.9907 - val_loss: 0.4940 - val_accuracy: 0.9041 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9823\n",
            "Epoch 32: val_accuracy did not improve from 0.92030\n",
            "57/57 [==============================] - 24s 426ms/step - loss: 0.0555 - accuracy: 0.9823 - val_loss: 0.4462 - val_accuracy: 0.9103 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "57/57 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9868\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.92030\n",
            "57/57 [==============================] - 24s 426ms/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.4678 - val_accuracy: 0.9004 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d5faee580>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('/content/model_checkpoint.h5')"
      ],
      "metadata": {
        "id": "w7YgbNlO1iZy"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = preprocess_data(test['data'], chr2indx)\n",
        "y_test = test['labels']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joaEe-O82x2Z",
        "outputId": "a409f407-618d-487f-abf3-3a2b3fd31b0d"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 lines in the data:\n",
            " ['لا يختشي ملاعب الظنون  والأمر مبنيٌّ على السكون', 'تُذَكِّرُني راحَةَ أَهلِ البِلى  أَرواحُ لَيلٍ بِخُزامى هَبَبنَ', 'خَليلَيَّ لَو كُنتُ الصَحيحَ وَكُنتُما  سَقيمَينِ لَم أَفعَل كَفِعلِكُما بِيا', 'هَمّي مِنَ الدُنيا خُلُوّي بِها  بِذاكَ أَدعو خالِقي في الصَلاة', 'يوم يقول لك السرور به اقترح  ما شئت من بيض الأماني يفعل', 'يَتَحَيَّرُ الراؤُونَ في نَعتَيهِما  أَصفاءُ ماءٍ أم صَفاءُ دَرارِ', 'أَضِنُّ عَن الدُنيا بِطَرفي وَطَرفِها  فَهَل بَعدَ هَذا مِن مَقالٍ لِمُشفِقِ', 'قد شَرد عن جَفْني غُمضى  حتّى ائتلفَتْ لِيَ شُرَّده', 'وَأَغَرَّ أَروَعَ مِلءِ سَمعِ المُنتَقى  حُرِّ الكَلامِ وَمِلءِ عَينِ المُبصِرِ', 'رَبَّةَ الدَّوْلَةِ وَالجَاهِ المَكِينْ  عُدْتِ يَحْدُو رَكْبَكِ الرُّوحُ الأَمِينْ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JF0uMUN1-Pk",
        "outputId": "cbc4fedd-a74b-4fb5-9aaf-e503efacdaf6"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 139ms/step - loss: 0.3639 - accuracy: 0.9294\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.363949179649353, 0.9293721914291382]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    }
  ]
}